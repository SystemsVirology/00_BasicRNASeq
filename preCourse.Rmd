---
title: "Prerequisites for the course"
output:
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Welcome to the transcriptomics data analysis training course. This course is designed to focus on the downstream analysis of transcriptomic data, including normalization, differential expression analysis, functional enrichment, and data visualization. To ensure a smooth learning experience, it is essential that participants have a foundational understanding of the upstream processes, such as quality assessment of raw sequencing data (FASTQ files), adapter trimming, sequence alignment, and read counting. These preliminary steps are crucial for generating high-quality data that will be used in downstream analyses. Therefore, before beginning this course, students are expected to familiarize themselves with these processes through independent study or prior training. These topics are covered in the previous weeks and it is better to refresh your understanding before starting this course. A very basic overview of the topics needed for this course are given below.

## The fastq file format

The FASTQ file format is a widely used format in bioinformatics for storing raw sequencing data from high-throughput sequencing technologies. Each entry in a FASTQ file corresponds to a single sequencing read and is composed of four lines. The first line begins with an "@" symbol followed by a unique identifier for the read. The second line contains the nucleotide sequence (A, T, C, G) of the read. The third line starts with a "+" symbol and may repeat the read identifier or be left blank. The fourth line contains the quality scores, which are represented as a string of ASCII characters corresponding to the probability that each nucleotide in the sequence is incorrect. These quality scores are critical for assessing the accuracy of the sequencing data and for downstream processes such as trimming and alignment. More information about fastq file formats can be read [here](https://knowledge.illumina.com/software/general/software-general-reference_material-list/000002211) and [here](https://en.wikipedia.org/wiki/FASTQ_format)

### The Phred quality score

The Phred quality score is a crucial metric used in sequencing technologies to assess the accuracy of nucleotide identification in DNA sequences. The Phred score quantifies the probability that a particular base is called incorrectly by the sequencer. Specifically, a higher Phred score indicates a lower likelihood of error, with the score being logarithmically related to the error probability. For instance, a Phred score of 20 corresponds to a 1 in 100 chance of an incorrect base call, while a score of 30 indicates a 1 in 1,000 chance. This scoring system is vital in bioinformatics for filtering and trimming low-quality sequences, ensuring that downstream analyses, such as alignment and variant calling, are based on the most reliable data possible. More information can be found [here](https://www.illumina.com/science/technology/next-generation-sequencing/plan-experiments/quality-scores.html) and [here](https://drive5.com/usearch/manual/quality_score.html)

## Fastq quality check

FastQC is a widely used tool for assessing the quality of high-throughput sequencing data. It provides a comprehensive overview of various quality metrics through a series of visualizations and reports. By analyzing raw sequencing files, FastQC evaluates key aspects such as base quality scores, GC content, sequence duplication levels, and overrepresented sequences. This allows researchers to identify potential issues, such as sequencing errors or contamination, early in the data analysis pipeline. The tool generates easy-to-interpret HTML reports, making it accessible for both novice and experienced users. For more detailed guidance, refer to the FastQC documentation and user guide available on the [FastQC website](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/).

## Pre-processing fastq files

Preprocessing FASTQ files is a crucial step in the sequencing data analysis pipeline, essential for ensuring the accuracy and reliability of downstream results. This process involves several key tasks: quality control, adapter trimming, and read filtering, which collectively enhance the overall quality of the data. Raw sequencing reads often contain low-quality bases, adapter sequences, and other contaminants that can lead to errors in subsequent analyses. Commonly used tools to perform pre-processing are Cutadapt, Trim Galore, and Trimmomatic. Cutadapt is widely used for removing adapter sequences from the ends of reads, effectively mitigating the risk of false-positive results caused by residual adapters. Trim Galore combines the functionalities of Cutadapt with additional trimming capabilities, focusing on removing low-quality bases and trimming reads to a consistent length. Trimmomatic is another popular tool that provides a range of trimming options, including the removal of adapter sequences, filtering of low-quality reads, and clipping of bases from both ends of the read based on user-defined quality thresholds. For further details, you can refer to the respective documentation and user guides available on the [Cutadapt website](https://cutadapt.readthedocs.io/en/stable/), [Trim Galore website](https://github.com/FelixKrueger/TrimGalore), and [Trimmomatic website](http://www.usadellab.org/cms/?page=trimmomatic).

## Read alignment

Aligning transcriptomic reads against a reference genome is a fundamental step in transcriptomics that facilitates the accurate mapping of RNA sequencing (RNA-seq) data (the reads) to known genomic locations. This alignment process is crucial for translating raw sequencing data into meaningful biological insights. By aligning reads to a reference genome, researchers can identify where each read originates, determine gene expression levels, and detect alternative splicing events, gene fusions, and other genomic variations. Accurate alignment is essential for quantifying gene expression accurately, as it ensures that reads are properly assigned to their corresponding genes or transcripts. Commonly used tools for read alignment include STAR (Spliced Transcripts Alignment to a Reference), which excels in handling large-scale RNA-seq datasets and complex splicing events, and HISAT2, which efficiently aligns reads to the genome while accommodating for splicing and structural variations. TopHat2, an earlier tool in this domain, is also used but is largely superseded by STAR and HISAT2 in modern workflows. These alignment tools employ sophisticated algorithms to map reads with high sensitivity and specificity, considering the complexities of spliced and overlapping transcripts. Successful alignment enables accurate downstream analyses such as differential expression studies, functional annotation, and pathway analysis. For more detailed guidance on these tools, consult the documentation and user guides available here, [STAR](https://github.com/alexdobin/STAR) , [HISAT2](http://daehwankimlab.github.io/hisat2/), [TopHat2](https://ccb.jhu.edu/software/tophat/index.shtml).

### Reference genome

The reference genome serves as a critical framework for mapping and interpreting sequencing data. For humans, the most widely used reference genome is GRCh38, the latest version of the Human Genome Reference Consortiumâ€™s (HGNC) assembly, which represents the human genome with a high degree of accuracy and completeness. Prior versions, such as GRCh37 (also known as hg19), are still in use but are gradually being phased out in favor of the more recent GRCh38, which includes improvements in genome assembly and annotation, including updated sequences for previously problematic regions and additional alternate loci.

The human reference genome can be obtained from several authoritative sources. The **Genome Reference Consortium (GRC)** provides the latest versions of the human reference genome, including GRCh38, through their official website. Additionally, the **Ensembl Genome Browser** offers access to various reference genome assemblies and annotations, including GRCh38 and its predecessors. For researchers looking for broader genome datasets, **NCBI (National Center for Biotechnology Information)** provides reference genome sequences through its **Genome** database, where users can download FASTA files and annotation data. Furthermore, the **UCSC Genome Browser** offers various human genome versions along with a range of tools for visualizing and accessing genomic data. These resources provide comprehensive and up-to-date reference genomes suitable for a wide range of genomic analyses.

### Gene model

A reference genome is annotated with a gene model that provides a detailed description of the gene structures within the genome. This model includes information on gene locations, exon-intron boundaries, and the transcriptional start and end sites. The gene model is crucial for understanding gene function and regulation and is typically represented in annotation files such as GTF (Gene Transfer Format) and GFF (General Feature Format). Both file formats provide similar types of information but have different syntaxes and are used in various tools and databases.

The GTF file format specifies the gene structures with fields such as gene ID, transcript ID, exon coordinates, and associated attributes, offering a structured way to describe gene features and their relationships. Similarly, GFF files include a broader range of annotations, including gene features, regulatory elements, and other genomic features. Both formats are essential for downstream analyses such as read alignment, gene expression quantification, and variant detection, as they allow researchers to map sequencing reads accurately to known genes and interpret functional elements in the genome. For more information, refer to the Ensembl GTF documentation and GFF specifications [here](https://useast.ensembl.org/info/website/upload/gff.html).

## Read counting

Read counting is a pivotal step in differential expression analysis, which involves quantifying the number of sequencing reads that map to each gene or transcript after alignment to a reference genome. This quantification is crucial for determining gene expression levels and comparing them across different experimental conditions or treatments. Accurate read counting enables researchers to identify genes that are differentially expressed, which can provide insights into biological processes and underlying mechanisms of disease. Commonly used tools for read counting include **HTSeq**, which parses aligned read data in BAM format and counts reads overlapping with annotated features from GTF or GFF files, and **featureCounts**, a part of the **Subread** package, which is known for its efficiency and accuracy in counting reads for large-scale RNA-seq datasets. Another popular tool is **RSEM (RNA-Seq by Expectation-Maximization)**, which not only counts reads but also estimates transcript abundances, accounting for multi-mapping reads and transcript isoforms. These tools provide essential input for statistical analyses, such as those performed by DESeq2 or edgeR, which further assess differential expression by normalizing counts and applying statistical models to determine significance. Accurate and reliable read counting is thus fundamental for drawing meaningful conclusions from RNA-seq data and advancing our understanding of gene expression regulation. For detailed information on these tools, refer to the [HTSeq documentation](https://htseq.readthedocs.io/en/latest/), the [featureCounts manual](https://subread.sourceforge.net/featureCounts.html), and the [RSEM website](https://github.com/bli25/RSEM_tutorial).





